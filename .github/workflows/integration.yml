name: Integration Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:  # Manual trigger

env:
  TESSELLATION_VERSION: v4.0.0-rc.2
  NODE_VERSION: '20'
  JAVA_VERSION: '21'

jobs:
  integration-test:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: ottochain
          POSTGRES_PASSWORD: ottochain
          POSTGRES_DB: ottochain
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U ottochain -d ottochain"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout ottochain-services
        uses: actions/checkout@v4

      - name: Checkout ottochain
        uses: actions/checkout@v4
        with:
          repository: scasplte2/ottochain
          path: ottochain
          ref: main

      - name: Checkout tessellation
        uses: actions/checkout@v4
        with:
          repository: Constellation-Labs/tessellation
          path: tessellation
          ref: ${{ env.TESSELLATION_VERSION }}

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: ${{ env.JAVA_VERSION }}
          cache: sbt

      - name: Setup sbt
        uses: sbt/setup-sbt@v1

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Get pnpm store directory
        shell: bash
        run: echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Cache pnpm
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: pnpm-${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: pnpm-${{ runner.os }}-

      - name: Install dependencies
        run: pnpm install

      - name: Build services
        run: pnpm build

      - name: Push database schema
        env:
          DATABASE_URL: postgresql://ottochain:ottochain@localhost:5432/ottochain
        run: pnpm db:push --skip-generate

      - name: Cache tessellation assemblies
        uses: actions/cache@v4
        with:
          path: |
            tessellation/modules/*/target
            tessellation/docker/jars
          key: tessellation-${{ env.TESSELLATION_VERSION }}-${{ hashFiles('tessellation/build.sbt') }}
          restore-keys: |
            tessellation-${{ env.TESSELLATION_VERSION }}-

      - name: Build tessellation
        working-directory: tessellation
        run: |
          # Note: dataL1 doesn't exist in tessellation - it's built from the metagraph (ottochain)
          sbt "sdk/publishLocal; keytool/assembly; wallet/assembly; shared/assembly; \
               dagL0/assembly; dagL1/assembly; currencyL0/assembly; currencyL1/assembly"
          mkdir -p docker/jars
          cp modules/keytool/target/scala-2.13/tessellation-keytool-assembly*.jar docker/jars/keytool.jar
          cp modules/wallet/target/scala-2.13/tessellation-wallet-assembly*.jar docker/jars/wallet.jar
          cp modules/dag-l0/target/scala-2.13/tessellation-dag-l0-assembly*.jar docker/jars/gl0.jar
          cp modules/dag-l1/target/scala-2.13/tessellation-dag-l1-assembly*.jar docker/jars/gl1.jar
          cp modules/currency-l0/target/scala-2.13/tessellation-currency-l0-assembly*.jar docker/jars/ml0.jar
          cp modules/currency-l1/target/scala-2.13/tessellation-currency-l1-assembly*.jar docker/jars/cl1.jar

      - name: Cache ottochain assemblies
        uses: actions/cache@v4
        with:
          path: |
            ottochain/modules/*/target
          key: ottochain-${{ hashFiles('ottochain/build.sbt', 'ottochain/project/*.sbt', 'ottochain/project/*.scala') }}
          restore-keys: ottochain-

      - name: Build ottochain metagraph
        working-directory: ottochain
        run: |
          sbt "currencyL0/assembly; dataL1/assembly"

      - name: Verify test keys exist and are different
        working-directory: tessellation/docker
        run: |
          echo "=== Verifying test keys in tessellation repo ==="
          
          # Check that local-test-keys exist
          if [ ! -d "config/local-test-keys/0" ]; then
            echo "ERROR: local-test-keys not found!"
            exit 1
          fi
          
          # Verify all 3 keys exist and are different
          PEER_IDS=()
          for i in 0 1 2; do
            if [ ! -f "config/local-test-keys/$i/key.p12" ]; then
              echo "ERROR: Key $i not found!"
              exit 1
            fi
            peer_id=$(cat config/local-test-keys/$i/peer_id)
            echo "Key $i peer_id: $peer_id"
            PEER_IDS+=("$peer_id")
          done
          
          # Check all peer IDs are unique
          unique_count=$(printf '%s\n' "${PEER_IDS[@]}" | sort -u | wc -l)
          if [ "$unique_count" != "3" ]; then
            echo "ERROR: Not all peer IDs are unique! Found $unique_count unique IDs"
            exit 1
          fi
          
          echo "✓ All 3 test keys verified as unique"

      - name: Start metagraph cluster
        working-directory: tessellation/docker
        run: |
          # Ensure scripts are executable (git checkout can lose permissions)
          chmod +x bin/*.sh
          
          # Enable webhook feature by adding WEBHOOK_URL to ml0 environment in compose file
          # The actual callback URL is registered via API; this just enables the feature
          sed -i 's/- CL_DOCKER_ID=ml0/- WEBHOOK_URL=http:\/\/webhook-enabled\/\n      - CL_DOCKER_ID=ml0/' docker-compose.metagraph.yaml
          
          # Verify the change was applied
          grep WEBHOOK_URL docker-compose.metagraph.yaml || echo "WARNING: WEBHOOK_URL not added!"
          
          # Use compose-runner which handles key generation, env setup, and container orchestration
          # --skip-assembly since we already built everything in prior steps
          ./bin/compose-runner.sh --up --metagraph=$(pwd)/../../ottochain --dl1 --skip-assembly

      - name: Verify key distribution
        working-directory: tessellation
        run: |
          echo "=== Verifying keys were distributed to node directories ==="
          
          for i in 0 1 2; do
            echo "--- Node $i ---"
            
            # Check key.p12 exists
            if [ ! -f "nodes/$i/key.p12" ]; then
              echo "ERROR: nodes/$i/key.p12 not found!"
              ls -la nodes/$i/ || true
              exit 1
            fi
            
            # Show key hash to verify they're different
            key_hash=$(md5sum nodes/$i/key.p12 | cut -d' ' -f1)
            echo "Key hash: $key_hash"
            
            # Show peer_id if available
            if [ -f "nodes/$i/peer_id" ]; then
              echo "Peer ID: $(cat nodes/$i/peer_id)"
            fi
            
            # Check .env has correct settings
            if [ -f "nodes/$i/.env" ]; then
              echo "Container suffix: $(grep CONTAINER_NAME_SUFFIX nodes/$i/.env || echo 'not set')"
              echo "DL1 join: $(grep CL_DOCKER_DL1_JOIN nodes/$i/.env || echo 'not set')"
              echo "DL1 genesis: $(grep CL_DOCKER_DL1_GENESIS nodes/$i/.env || echo 'not set')"
            fi
            echo ""
          done
          
          # Verify all key hashes are unique
          hash0=$(md5sum nodes/0/key.p12 | cut -d' ' -f1)
          hash1=$(md5sum nodes/1/key.p12 | cut -d' ' -f1)
          hash2=$(md5sum nodes/2/key.p12 | cut -d' ' -f1)
          
          if [ "$hash0" = "$hash1" ] || [ "$hash0" = "$hash2" ] || [ "$hash1" = "$hash2" ]; then
            echo "ERROR: Key hashes are not all unique!"
            echo "Node 0: $hash0"
            echo "Node 1: $hash1"
            echo "Node 2: $hash2"
            exit 1
          fi
          
          echo "✓ All node keys verified as unique"

      - name: Wait for metagraph healthy
        run: |
          echo "=== Waiting for GL0 ==="
          for i in {1..90}; do
            if curl -s http://localhost:9000/node/info | grep -q '"state":"Ready"'; then
              echo "GL0 ready after ${i}s"
              break
            fi
            sleep 1
            if [ $i -eq 90 ]; then echo "GL0 timeout"; docker logs gl0-0 2>&1 | tail -30 || true; exit 1; fi
          done
          
          echo "=== Waiting for ML0 (may take longer on CI) ==="
          for i in {1..180}; do
            if curl -s http://localhost:9200/node/info | grep -q '"state":"Ready"'; then
              echo "ML0 ready after ${i}s"
              break
            fi
            sleep 1
            if [ $i -eq 180 ]; then echo "ML0 timeout"; docker logs ml0-0 2>&1 | tail -30 || true; exit 1; fi
          done
          
          echo "=== Waiting for DL1 ==="
          for i in {1..180}; do
            if curl -s http://localhost:9400/node/info | grep -q '"state":"Ready"'; then
              echo "DL1 ready after ${i}s"
              break
            fi
            sleep 1
            if [ $i -eq 180 ]; then echo "DL1 timeout"; docker logs dl1-0 2>&1 | tail -30 || true; exit 1; fi
          done
          
          echo "=== Waiting for first metagraph snapshot ==="
          # Use /snapshots/latest (ML0's own snapshots) NOT /global-snapshots/latest (synced from GL0)
          for i in {1..120}; do
            ordinal=$(curl -s http://localhost:9200/snapshots/latest | jq -r '.value.ordinal // 0' 2>/dev/null || echo "0")
            if [ "$ordinal" -gt 0 ]; then
              echo "Metagraph producing snapshots (ordinal: $ordinal) after ${i}s"
              exit 0
            fi
            sleep 1
          done
          echo "Metagraph not producing snapshots"
          echo "=== ML0 /snapshots/latest response ==="
          curl -s http://localhost:9200/snapshots/latest | jq . || true
          echo "=== ML0 logs ==="
          docker logs ml0-0 2>&1 | tail -50 || true
          exit 1

      - name: Verify DL1 cluster formation
        run: |
          echo "=== Verifying DL1 cluster has multiple unique peers ==="
          
          # Get peer IDs from each DL1 node
          PEER_0=$(curl -s http://localhost:9400/node/info | jq -r '.id // "error"' 2>/dev/null || echo "unreachable")
          PEER_1=$(curl -s http://localhost:9410/node/info | jq -r '.id // "error"' 2>/dev/null || echo "unreachable")
          PEER_2=$(curl -s http://localhost:9420/node/info | jq -r '.id // "error"' 2>/dev/null || echo "unreachable")
          
          echo "DL1-0 (port 9400): ${PEER_0:0:32}..."
          echo "DL1-1 (port 9410): ${PEER_1:0:32}..."
          echo "DL1-2 (port 9420): ${PEER_2:0:32}..."
          
          # Check if all peer IDs are unique (the core issue we're fixing)
          if [ "$PEER_0" = "$PEER_1" ] || [ "$PEER_0" = "$PEER_2" ] || [ "$PEER_1" = "$PEER_2" ]; then
            echo ""
            echo "❌ ERROR: DL1 nodes have DUPLICATE peer IDs!"
            echo "This means all nodes are using the same key.p12 file."
            echo ""
            echo "=== Container volume mounts ==="
            for c in dl1-0 dl1-1 dl1-2; do
              echo "--- $c ---"
              docker inspect $c --format '{{range .Mounts}}{{.Source}} -> {{.Destination}}{{"\n"}}{{end}}' 2>/dev/null | grep key || echo "no key mount found"
            done
            echo ""
            echo "=== Key files on disk ==="
            for i in 0 1 2; do
              if [ -f "tessellation/nodes/$i/key.p12" ]; then
                echo "nodes/$i/key.p12: $(md5sum tessellation/nodes/$i/key.p12 | cut -d' ' -f1)"
              else
                echo "nodes/$i/key.p12: NOT FOUND"
              fi
            done
            exit 1
          fi
          
          echo "✓ All DL1 nodes have unique peer IDs"
          
          # Get cluster info from DL1
          cluster_size=$(curl -s http://localhost:9400/cluster/info | jq 'length' 2>/dev/null || echo "0")
          echo "DL1 cluster size: $cluster_size"
          
          if [ "$cluster_size" -lt 2 ]; then
            echo "WARNING: DL1 cluster has fewer than 2 peers - nodes may not have joined"
            echo "=== DL1-0 cluster info ==="
            curl -s http://localhost:9400/cluster/info | jq . || true
          else
            echo "✓ DL1 cluster has $cluster_size peers"
          fi

      - name: Start Redis
        run: |
          docker run -d --name redis-ci -p 6379:6379 redis:alpine
          sleep 2
          docker exec redis-ci redis-cli ping

      - name: Build services Docker image
        run: |
          docker build -t ottochain-services:ci .
          echo "SERVICES_IMAGE=ottochain-services:ci" >> $GITHUB_ENV

      - name: Start services containers
        run: |
          # Start indexer and bridge as containers on tessellation_common network
          # This allows ML0 to reach them directly without proxy hacks
          docker compose -f docker-compose.ci.yaml up -d
          
          # Wait for services to be healthy
          echo "Waiting for services to be healthy..."
          for i in {1..60}; do
            indexer_ok=$(curl -sf http://localhost:3031/health 2>/dev/null | grep -c '"status":"ok"' || echo "0")
            bridge_ok=$(curl -sf http://localhost:3030/health 2>/dev/null | grep -c '"status":"ok"' || echo "0")
            
            if [ "$indexer_ok" = "1" ] && [ "$bridge_ok" = "1" ]; then
              echo "✓ Both services healthy after ${i}s"
              break
            fi
            
            if [ $i -eq 60 ]; then
              echo "❌ Services failed to become healthy"
              docker compose -f docker-compose.ci.yaml logs
              exit 1
            fi
            sleep 1
          done
          
          # Verify ML0 can reach indexer directly (no proxy needed!)
          docker exec ml0-0 curl -sf http://indexer:3031/health
          echo "✓ ML0 can reach indexer directly on tessellation_common network"

      - name: Run webhook integration tests
        env:
          ML0_URL: http://localhost:9200
          INDEXER_URL: http://localhost:3031
          # Use 'indexer' hostname since tests run subscription from ML0's perspective
          HOST_IP: indexer
        run: npx tsx scripts/test-webhook.ts

      - name: Run traffic generator integration test
        env:
          BRIDGE_URL: http://localhost:3030
          ML0_URL: http://localhost:9200
          INDEXER_URL: http://localhost:3031
          FIBER_WAIT_TIMEOUT: '90'
          DL1_SYNC_WAIT: '15'
          ACTIVATION_WAIT: '10'
          INDEXER_WAIT_TIMEOUT: '30000'
          MAX_RETRIES: '5'
        run: |
          # Retry logic for flaky metagraph consensus timing
          for attempt in $(seq 1 $MAX_RETRIES); do
            echo "=== Attempt $attempt of $MAX_RETRIES ==="
            if npx tsx packages/traffic-generator/test/integration.test.ts; then
              echo "✓ Test passed on attempt $attempt"
              exit 0
            fi
            if [ $attempt -lt $MAX_RETRIES ]; then
              echo "⚠️ Test failed, waiting 10s before retry..."
              sleep 10
            fi
          done
          echo "❌ All $MAX_RETRIES attempts failed"
          exit 1

      - name: Collect logs on failure
        if: failure()
        run: |
          echo "=== Container list ==="
          docker ps -a || true
          
          echo "=== Container volume mounts ==="
          for container in gl0-0 ml0-0 dl1-0 dl1-1 dl1-2 cl1-0 cl1-1 cl1-2; do
            echo "--- $container ---"
            docker inspect $container --format '{{range .Mounts}}{{.Source}} -> {{.Destination}}{{"\n"}}{{end}}' 2>/dev/null || echo "not found"
          done
          
          echo "=== DL1 Peer IDs (from logs) ==="
          for container in dl1-0 dl1-1 dl1-2; do
            echo "--- $container ---"
            docker logs $container 2>&1 | grep -i "Self peerId\|Majority Peer\|Join" | head -5 || true
          done
          
          echo "=== GL0 Logs ==="
          docker logs gl0-0 2>&1 | tail -100 || true
          echo "=== ML0 Logs ==="
          docker logs ml0-0 2>&1 | tail -100 || true
          echo "=== DL1-0 Logs ==="
          docker logs dl1-0 2>&1 | tail -100 || true
          echo "=== DL1-1 Logs ==="
          docker logs dl1-1 2>&1 | tail -50 || true
          echo "=== DL1-2 Logs ==="
          docker logs dl1-2 2>&1 | tail -50 || true
          echo "=== Indexer Logs ==="
          docker logs indexer 2>&1 | tail -100 || true
          echo "=== Bridge Logs ==="
          docker logs bridge 2>&1 | tail -50 || true
          echo "=== Webhook Subscribers ==="
          curl -s http://localhost:9200/data-application/v1/webhooks/subscribers | jq . || true

      - name: Cleanup
        if: always()
        run: |
          # Stop services containers
          docker compose -f docker-compose.ci.yaml down 2>/dev/null || true
          docker rm -f redis-ci 2>/dev/null || true
          # Stop tessellation cluster
          cd tessellation/docker
          chmod +x bin/*.sh 2>/dev/null || true
          ./bin/compose-runner.sh --down || true
